### Data
## Technical description
Data Source 1
The first dataset we use is the United States Cancer Statistics (USCS) from the CDC's WONDER database(https://wonder.cdc.gov/cancer-v2020.HTML). It includes cancer incidence data for the United States. These data are collected and provided by the CDC's National Program of Cancer Registries (NPCR) and the National Cancer Institute's Surveillance, Epidemiology and End Results (SEER) program. From the previous archived Cancer Statistics data, we can tell that the dataset is updated each year. The data contains 9 variables, including location, year, age group, race, sex, ethnicity, leading cancer sites, cancer sites, and childhood cancers. Also, the dataset covers years 1999 to 2020, with the 2022 data submission released in 2023. One problem with the data source is that we cannot save the data as csv file directly. Instead, we need to use the query provided by the website to select the specific columns we want and save it in a txt file. For our research purpose, we only include year from 2001 to 2011, sex, states, specific cancers(Brain, kidney and renal pelvis, larynx, lung, melanoma of the skin, and oral cancer). The dataset includes the total population, the number of people who get cancer, and the crude rate. To import the data, we need to use R to transform it to csv file. 

```{r}
library(readr)

data <- read.table(file = 'United States Cancer Statistics, 2002-2011 Incidence.txt', 
                   header = TRUE, 
                   fill = TRUE, 
                   strip.white = TRUE, 
                   sep = "")
data <- data[, -ncol(data)]
names(data)[ncol(data)] <- 'Crude Rate'
write_csv(data, 'cancer.csv')

```

Data Source 2
Daily PM2.5 Concentrations All County, 2001-2016
LINK: https://data.cdc.gov/Environmental-Health-Toxicology/Daily-PM2-5-Concentrations-All-County-2001-2016/7vdq-ztk9
This data set is collected by CDC National Environmental Public Health Tracking Network. It provides modeled predictions of PM2.5 levels from the EPA's Downscaler model. Data are at the county level for year 2001-2016. The dataset includes the maximum, median, mean, and population-weighted mean of 24-hour average PM2.5 concentration in Î¼g/m3. This data set is in csv format. It was created on March 25, 2020 and last updated on January 21, 2021. 
Original Data Dimension: 18.2M rows and 8 columns.
Since this dataset is too large, I wouldn't be able to directly download and import from the Centers for Disease Control and Prevention website. Also, to compare with cancer incidence over time, it's better to let both datasets have the same time division (i.e., by year) and same geographical division(i.e., by state), it ensures consistency in the temporal granularity of the data. Thus, I will first group by year and state and aggregate on the PM25_max_pred and PM25_pop_pred columns to make the row number smaller using the query tools on the website and then import using API endpoint. 

```{r}
pm <- read.csv("https://data.cdc.gov/resource/7vdq-ztk9.csv?$query=SELECT%0A%20%20%60year%60%2C%0A%20%20%60statefips%60%2C%0A%20%20max(%60pm25_max_pred%60)%20AS%20%60max_pm25_max_pred%60%2C%0A%20%20avg(%60pm25_pop_pred%60)%20AS%20%60avg_pm25_pop_pred%60%0AGROUP%20BY%20%60year%60%2C%20%60statefips%60")
```

Data Source 3
Daily County-Level Ozone Concentrations, 2001-2016
LINK: https://data.cdc.gov/Environmental-Health-Toxicology/Daily-County-Level-Ozone-Concentrations-2001-2016/kmf5-t9yc
This data set is collected by CDC National Environmental Public Health Tracking Network. Data are at the county levels for years 2001-2014. The dataset includes the maximum, median, mean, and population-weighted mean estimated 8-hour average ozone concentration in parts per billion (ppb) within 3 meters of the surface of the earth. This data set is in csv format. It was created on March 11, 2020 and last updated on May 21, 2020. 
Original Data Dimension: 18.2M rows and 9 columns
Since the data set is too large, I wouldn't be able to directly download and import from the Centers for Disease Control and Prevention website. For the consistency purpose mentioned above, I will first group by year and state and aggregate on 03_max_pred and O3_pop_pred columns to make the row number smaller using the query tools on the website and then import using API endpoint.

```{r}
ozone <- read.csv("https://data.cdc.gov/resource/kmf5-t9yc.csv?$query=SELECT%0A%20%20%60year2%60%2C%0A%20%20%60statefips%60%2C%0A%20%20max(%60o3_max_pred%60)%20AS%20%60max_o3_max_pred%60%2C%0A%20%20avg(%60o3_pop_pred%60)%20AS%20%60avg_o3_pop_pred%60%0AGROUP%20BY%20%60year2%60%2C%20%60statefips%60")
```

## Research plan
To answer what geographical areas in the United States have consistently poor air quality and elevated cancer rates. We would perform time series analysis and draw time series line plot. Also, we will use box plot to get a summary of air quality data for multiple regions in a compact format. Each box plot represents a region, and the boxes display the distribution of air quality values (e.g., median, quartiles). Regions with consistently poor air quality will have lower medians and wider interquartile ranges. To double check our finding, we would use heatmap to visualize air quality data across both time and regions. Rows represent regions, columns represent time intervals, and the color scale indicates air quality levels. Consistently poor air quality regions will be represented by darker colors on the heatmap.

## Missing value analysis
Load required libraries
```{r, include=FALSE}
library(dplyr)
library(ggplot2)
library(reshape2)
library(tidyverse)
library(mi)
library(redav)
```
```{r}
library(dplyr)
library(ggplot2)
library(reshape2)
library(tidyverse)
library(mi)
library(redav)
```

For the cancer dataset, from the description of the website, all missing and null values are shown as "Missing" in the dataset. Here I convert all "Missing" values to NA and show them in graph. 
```{r}
data <- data %>%
  mutate(across(where(is.character), ~na_if(., "Missing")))
```

```{r}
colSums(is.na(data))
```
It seems like the number of null values in the cancer data frame is not large. Here we want to find which rows contains the null values. 

```{r}
# Get the row indices that have any NA values
na_rows <- which(apply(is.na(data), 1, any), arr.ind=TRUE)
selected_rows <- data[na_rows, ]
selected_rows
```
From the graph we find that all values of count, population and crude rate in 2002 and Mississippi are missing. 

```{r}
x <- missing_data.frame(data)
image(x)
```
```{r}
plot_missing(data, percent = FALSE)
levels(x@patterns)
summary(x@patterns)
```
From the graph we can see that only columns of count, population, and crude rate have missing values. And all missing values are from the state of Mississipi during the year of 2002. 

For the PM2.5 Concentrations dataset:
```{r}
colSums(is.na (pm) ) |> sort(decreasing = TRUE)
```
```{r}
plot_missing(pm, percent = FALSE)
```
Based on the missing pattern graph and the NA count in the dataset, there is no missing values.

For the Ozone Concentrations dataset: 
```{r}
colSums(is.na (ozone) ) |> sort(decreasing = TRUE)
```
```{r}
plot_missing(ozone, percent = FALSE)
```
Based on the missing pattern graph and the NA count in the dataset, there is no missing values.
